{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<small><font color=gray>Notebook author: <a href=\"https://www.linkedin.com/in/olegmelnikov/\" target=\"_blank\">Oleg Melnikov</a>, ¬©<a href=\"https://apps.ep.jhu.edu/course-homepages/3765-605-742-deep-neural-networks\" target=\"_blank\">JHU</a> 2021 onwards</font></small><hr style=\"margin:0;background-color:silver\">\n",
        "\n",
        "# **[2üèÜüååStellar](https://www.kaggle.com/competitions/30jan23JH-stellar/rules)**\n",
        "\n",
        "See [**instructions**](https://colab.research.google.com/drive/1riOGrE_Fv-yfIbM5V4pgJx4DWcd92cZr#scrollTo=ITaPDPIQEgXV) for running and naming your Colab notebooks.\n",
        "\n"
      ],
      "metadata": {
        "id": "q3pqxgX4DxeH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(Optioal) CONSENT.** If ok with sharing your Colab for educational purposes, please check the box below with \"X\".\n",
        "\n",
        "<mark>[ .X. ]</mark> We consent to sharing our Colab (after the assignment ends) with other students/instructors for educational purpose. We understand that sharing is optional and this decision will not affect our grade in any way. "
      ],
      "metadata": {
        "id": "_dTfQBUZyNQK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive; drive.mount('/content/drive')   # OK to enable, if your kaggle.json is stored in Google Drive"
      ],
      "metadata": {
        "id": "qrogZ_8bD9tZ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8XoC8VqBXGs",
        "outputId": "0d3c3d52-08ab-434a-b4c2-d13772035d9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- competition is now set to: 30jan23cml-stellar\n"
          ]
        }
      ],
      "source": [
        "!pip -q install --upgrade --force-reinstall --no-deps kaggle > log  # upgrade kaggle package (to avoid a warning)\n",
        "!mkdir -p ~/.kaggle                                           # .kaggle folder must contain kaggle.json for kaggle executable to properly authenticate you to Kaggle.com\n",
        "!cp /content/kaggle.json ~/.kaggle/kaggle.json >log  # First, download kaggle.json from kaggle.com (in Account page) and place it in the root of mounted Google Drive\n",
        "!cp kaggle.json ~/.kaggle/kaggle.json > log                   # Alternative location of kaggle.json (without a connection to Google Drive)\n",
        "!chmod 600 ~/.kaggle/kaggle.json                              # give only the owner full read/write access to kaggle.json\n",
        "!kaggle config set -n competition -v 30jan23cml-stellar        # set the competition context for the next few kaggle API calls. !kaggle config view - shows current settings\n",
        "!kaggle competitions download >> log                          # download competition dataset as a zip file\n",
        "!unzip -o *.zip >> log                                        # Kaggle dataset is copied as a single file and needs to be unzipped.\n",
        "lb =!kaggle competitions leaderboard --show                   # print public leaderboard"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lb0 = [(int(l[:7]), l[9:60].strip(), l[60:80].strip(), float(l[81:].strip())) for l in lb[3:]]\n",
        "# dflb = pd.DataFrame(lb0, columns=['id','team','dt','score'])\n",
        "# dflb = dflb[dflb.team.str.contains('üêØ') | dflb.team.str.lower().str.contains('baseline')]\n",
        "# dflb.sort_values('dt', ascending=False)"
      ],
      "metadata": {
        "id": "yIUdGjSO24Ve"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "%%capture\n",
        "%reset -f\n",
        "# import pandas as pd\n",
        "# import sklearn\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "# from sklearn.preprocessing import LabelEncoder\n",
        "# from sklearn.neighbors import LocalOutlierFactor\n",
        "# from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "# from sklearn.model_selection import train_test_split\n",
        "from IPython.core.interactiveshell import InteractiveShell as IS; IS.ast_node_interactivity = \"all\" \n",
        "import numpy as np, pandas as pd, time, matplotlib.pyplot as plt, seaborn as sns, os, tqdm, re, sys, cv2, skimage\n",
        "# from sklearn.preprocessing import PolynomialFeatures\n",
        "# from sklearn.linear_model import LogisticRegression as LR\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
        "# from sklearn.linear_model import LogisticRegression\n",
        "# from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA, LinearDiscriminantAnalysis as LDA\n",
        "ToCSV = lambda df, fname: df.round(2).to_csv(f'{fname}.csv', index_label='id') # rounds values to 2 decimals\n",
        "\n",
        "class Timer():\n",
        "  def __init__(self, lim:'RunTimeLimit'=60): self.t0, self.lim, _ = time.time(), lim, print(f'‚è≥ started. You have {lim} sec. Good luck!')\n",
        "  def ShowTime(self):\n",
        "    msg = f'Runtime is {time.time()-self.t0:.0f} sec'\n",
        "    print(f'\\033[91m\\033[1m' + msg + f' > {self.lim} sec limit!!!\\033[0m' if (time.time()-self.t0-1) > self.lim else msg)\n",
        "\n",
        "np.set_printoptions(linewidth=100, precision=2, edgeitems=2, suppress=True)\n",
        "pd.set_option('max_columns', 20, 'precision', 2, 'display.max_rows', 4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CyC-JlZFga1",
        "outputId": "094888cf-4d71-454d-9657-6347555c706a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.36 s, sys: 152 ms, total: 1.51 s\n",
            "Wall time: 2.36 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df.info()   # observe datatypes and any missing values"
      ],
      "metadata": {
        "id": "fFp0IV3BJR9_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change string labels to numbers in order of increasing size of the entity (Star < Quasi Star < Galaxy)\n",
        "# df.Class = df.Class.apply(lambda C: -1 if C=='S' else 0 if C=='Q' else 1 if C=='G' else None) "
      ],
      "metadata": {
        "id": "UDA4wJqELlOR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vX = df.query('Class!=Class').drop('Class', axis=1)  # slice a test sample\n",
        "# tXY = df.query('Class==Class')                       # slice training sample\n",
        "# tX, tY = tXY.drop('Class', axis=1), tXY.Class        # split into training I/O"
      ],
      "metadata": {
        "id": "f7OuVizOFsFF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def ScatterCorrHist(df):\n",
        "#   def corrdot(*args, **kwargs):\n",
        "#     # credit: https://stackoverflow.com/questions/48139899\n",
        "#     corr_r = args[0].corr(args[1], 'pearson')\n",
        "#     corr_text = f\"{corr_r:2.2f}\".replace(\"0.\", \".\")\n",
        "#     ax = plt.gca();\n",
        "#     ax.set_axis_off();\n",
        "#     msz = abs(corr_r) * 5000   # marker size\n",
        "#     fsz = abs(corr_r) * 40 + 5 # font size\n",
        "#     ax.scatter([.5], [.5], msz, [corr_r], alpha=0.5, cmap='coolwarm', vmin=-1, vmax=1, transform=ax.transAxes)\n",
        "#     ax.annotate(corr_text, [.5, .5,],  xycoords=\"axes fraction\", ha='center', va='center', fontsize=fsz)\n",
        "\n",
        "#   sns.set(style='white', font_scale=.8);\n",
        "#   g = sns.PairGrid(df, aspect=1, diag_sharey=False);\n",
        "#   g.fig.set_size_inches(20,10)\n",
        "#   g.map_lower(sns.regplot, lowess=True, ci=False, line_kws={'color':'red'}, scatter_kws={'s':1});\n",
        "#   g.map_diag(sns.histplot, kde_kws={'color':'black'});\n",
        "#   g.map_upper(corrdot);\n",
        "#   g.fig.suptitle(\"Scatter plot, Correlations and histograms on diagonal\", y=1);\n",
        "#   _ = plt.subplots_adjust(hspace=0.02, wspace=0.02);\n",
        "#   _ = plt.show();\n",
        "\n",
        "# # ScatterCorrHist(tXY.head(200))"
      ],
      "metadata": {
        "id": "i4gelET6Hb2A"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tmr = Timer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4_C58bbHuja",
        "outputId": "268b38bc-fd6e-4053-b113-0da4aac8a365"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚è≥ started. You have 60 sec. Good luck!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr color=red>\n",
        "\n",
        "<font size=5>‚è≥</font> <strong><font color=orange size=5>Your Code, Documentation, Ideas and Timer - All Start Here...</font></strong>\n",
        "\n",
        "**Student's Section** (between ‚è≥ symbols): add your code and documentation here."
      ],
      "metadata": {
        "id": "3NcTKbw3KhAn"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpyLNt3god0c"
      },
      "source": [
        "## **Task 1. Preprocessing Pipeline**\n",
        " \n",
        "Explain elements of your preprocessing pipeline i.e. feature engineering, subsampling, clustering, dimensionality reduction, etc. \n",
        "1. Why did you choose these elements? (Something in EDA, prior experience,...? Btw, EDA is not required)\n",
        "1. How do you evaluate the effectiveness of these elements? \n",
        "1. What else have you tried that worked or didn't? "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "woK7Zf-wPtMy"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('XY_Stellar.csv')"
      ],
      "metadata": {
        "id": "wTVNKVQXPurq"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing = df[df['Class'] != df['Class']]\n",
        "testing = testing.drop('Class', axis=1)"
      ],
      "metadata": {
        "id": "KNAhjf9tPxhV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna()"
      ],
      "metadata": {
        "id": "kZGLCN_oPzSy"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enc1 = LabelEncoder()\n",
        "enc1.fit(df['Class'])\n",
        "df['Class'] = enc1.transform(df['Class'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdoEKNQcP00E",
        "outputId": "2e40f9cf-7a60-4517-a97f-4f7c77e2817d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LabelEncoder()"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "–£–¥–∞–ª–∏–º –±–µ—Å–ø–æ–ª–µ–∑–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏, –Ω–µ –¥–∞—é—â–∏–µ –Ω–∏–∫–∞–∫–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∫–ª–∞—Å—Å–∞."
      ],
      "metadata": {
        "id": "_7n713syTPmY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "testing = testing.drop(['alpha','delta','run_ID','cam_col','field_ID','fiber_ID'], axis = 1)"
      ],
      "metadata": {
        "id": "qRQiB8TxP2hi"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(['alpha','delta','run_ID','cam_col','field_ID','fiber_ID'], axis = 1)"
      ],
      "metadata": {
        "id": "98piEiCXP4Ga"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ü–æ—á–∏—Å—Ç–∏–º –¥–∞—Ç–∞—Å–µ—Ç –æ—Ç –≤—ã–±—Ä–æ—Å–æ–≤, –≤–ª–∏—è—é—â–∏—Ö –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–æ –æ–±—É—á–µ–Ω–∏—è. "
      ],
      "metadata": {
        "id": "GXbiSludTWpf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(df[(df['u'] < 0) | (df['u'] > 50)].index)\n",
        "df = df.drop(df[(df['r'] < 0) | (df['r'] > 40)].index)\n",
        "df = df.drop(df[(df['g'] < 0) | (df['g'] > 40)].index)\n",
        "df = df.drop(df[(df['i'] < 0) | (df['i'] > 40)].index)\n",
        "df = df.drop(df[(df['z'] < 0) | (df['z'] > 40)].index)"
      ],
      "metadata": {
        "id": "7A2TrAXf9_r1"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "–£–¥–∞–ª–∏–º –µ—â–µ –≤—ã–±—Ä–æ—Å—ã —Å –ø–æ–º–æ—â—å—é –≤—ã—è–≤–∏—Ç–µ–ª—è Outliers."
      ],
      "metadata": {
        "id": "XtC3rFMzTeWK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "clf = LocalOutlierFactor()\n",
        "y_pred = clf.fit_predict(df) "
      ],
      "metadata": {
        "id": "HfmWcCHH-BY5"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_score = clf.negative_outlier_factor_\n",
        "outlier_score = pd.DataFrame(x_score, index=df.index)"
      ],
      "metadata": {
        "id": "YfZXtqQxNPHV"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(outlier_score[outlier_score[0] < -2].index)"
      ],
      "metadata": {
        "id": "3CLUfBnwNQ1x"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_y = df['Class']\n",
        "df_x = df.drop('Class', axis=1)"
      ],
      "metadata": {
        "id": "KsOERy_W-GGN"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "–°–¥–µ–ª–∞–µ–º –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ –∏ –∑–∞—Å–∫–µ–π–ª–∏–º –¥–∞—Ç–∞—Å–µ—Ç."
      ],
      "metadata": {
        "id": "OOxMoAYVTjmb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(df_x)\n",
        "df_x = scaler.transform(df_x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MyWdZX3-IIm",
        "outputId": "64f3d955-2d9c-4eed-e882-6ae714f0eac6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StandardScaler()"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "–°–æ–∑–¥–∞–¥–∏–º –ø–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ 2 —Å—Ç–µ–ø–µ–Ω–∏."
      ],
      "metadata": {
        "id": "qgknmmrFTnrl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "poly = PolynomialFeatures(2).fit(df_x)\n",
        "df_x = poly.transform(df_x)"
      ],
      "metadata": {
        "id": "8SDxGvvS-Jll"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "–°–Ω–æ–≤–∞ –∑–∞—Å–∫–µ–π–ª–∏–º –¥–∞–Ω–Ω—ã–µ."
      ],
      "metadata": {
        "id": "7nLNA0oGTrHM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler_after = StandardScaler()\n",
        "scaler_after.fit(df_x)\n",
        "df_x = scaler_after.transform(df_x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxhaoP2c-K_i",
        "outputId": "c5e8caed-ab6c-4759-c4ef-829317ba0d6a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StandardScaler()"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testing = scaler.transform(testing)\n",
        "testing = poly.transform(testing)\n",
        "testing = scaler_after.transform(testing)"
      ],
      "metadata": {
        "id": "FEo7V0w3-MWv"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30xYIFXAnaPE"
      },
      "source": [
        "**Student's answer:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGJRwzqHob4o"
      },
      "source": [
        "## **Task 2. Modeling Approach**\n",
        "Explain your modeling approach, i.e. ideas you tried and why you thought they would be helpful. \n",
        "\n",
        "1. How did these decisions guide you in modeling?\n",
        "1. How do you evaluate the effectiveness of these elements? \n",
        "1. What else have you tried that worked or didn't? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJs0jS4fIO1j"
      },
      "source": [
        "Below is a baseline model that produces the result on Kaggle leaderboard (LB)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ú—ã –ø–æ–ø—Ä–æ–±–æ–≤–∞–ª–∏ –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ –≤ –¥–∞–Ω–Ω–æ–º —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏–∏, –Ω–æ –ª—É—á—à–∏–π —Å–∫–æ—Ä –ø–æ –¥–µ—Ñ–æ–ª—Ç—É –ø–æ–∫–∞–∑–∞–ª –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π –ª–æ–≥—Ä–µ–≥, –ø–æ—ç—Ç–æ–º—É –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ."
      ],
      "metadata": {
        "id": "xUOmgLfCTtKE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(df_x, df_y, test_size = 0.2, random_state = 99)"
      ],
      "metadata": {
        "id": "NG8G34rI-OVX"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dl = len(x_train) // 2\n",
        "x_train_first = x_train[:dl,]\n",
        "x_train_second = x_train[dl:,]\n",
        "y_train_first = y_train[:dl,]\n",
        "y_train_second = y_train[dl:,]"
      ],
      "metadata": {
        "id": "1JgO0AoS-P5N"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "–í–æ–∑—å–º–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä OneVSRest –∏ –æ–±—É—á–∏–º –µ–≥–æ –Ω–∞ –ø–æ–ª–æ–≤–∏–Ω–µ –¥–∞–Ω–Ω—ã—Ö."
      ],
      "metadata": {
        "id": "O_976BsbT2UG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "orc = OneVsRestClassifier(LogisticRegression(solver='lbfgs', max_iter=400, penalty='none', warm_start=True)).fit(x_train_first, y_train_first)\n",
        "\n",
        "sklearn.metrics.accuracy_score(y_test, orc.predict(x_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FikwdYAS-WqI",
        "outputId": "2722ae92-4fff-4525-d9e5-232e80f096e9"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9662079558634525"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_second = pd.DataFrame(x_train_second)\n",
        "x_train_second[45] = orc.predict(x_train_second)\n"
      ],
      "metadata": {
        "id": "hRFhxzSk-S6P"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test_new = pd.DataFrame(x_test).copy()\n",
        "x_test_new[45] = orc.predict(x_test)\n"
      ],
      "metadata": {
        "id": "rpo8uOAl-U4U"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "–î–∞–ª–µ–µ –ø—Ä–µ–¥—Å–∫–∞–∂–µ–º 1 –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–º –∫–ª–∞—Å—Å –Ω–∞ 2 –ø–æ–ª–æ–≤–∏–Ω–µ –∏ –ø–æ–¥–∞–¥–∏–º —ç—Ç–æ –≤ –æ–±—É—á–∞—é—â—É—é –≤—ã–±–æ—Ä–∫—É 2 –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ OneVsOne."
      ],
      "metadata": {
        "id": "qrgxdg4VT74B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
        "ooc = OneVsOneClassifier(\n",
        "    LogisticRegression(solver='lbfgs',\n",
        "                         penalty='none',\n",
        "                         max_iter=1000, #1200\n",
        "                         tol = 1e-4,\n",
        "                         random_state=69)).fit(x_train_second, y_train_second)\n",
        "\n",
        "sklearn.metrics.accuracy_score(y_test, ooc.predict(x_test_new))\n",
        "#0.9702830632268581"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1lfJU0d-aFz",
        "outputId": "c1f1a6e9-7e79-42c6-b481-499753d31717"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9704397981254506"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "–°–¥–µ–ª–∞–µ–º –ø—Ä–µ–¥–∏–∫—Ç."
      ],
      "metadata": {
        "id": "cCx5sCqQUGr4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "testing = pd.DataFrame(testing)\n"
      ],
      "metadata": {
        "id": "hbUG9AGX-gM2"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing[45] = orc.predict(testing)\n",
        "res = ooc.predict(testing)\n",
        "# pd.DataFrame(res)"
      ],
      "metadata": {
        "id": "qwdOUUjS-hrF"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ToCSV = lambda df, fname: df.to_csv(f'{fname}.csv', index_label='id')\n",
        "submit_final = pd.DataFrame(enc1.inverse_transform(ooc.predict(testing)), columns=['Class'])\n",
        "submit_final.index += 1\n",
        "ToCSV(submit_final, 'orc_ooc_1')"
      ],
      "metadata": {
        "id": "1ltniZcH-jx-"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zi6ZjgtWnb58"
      },
      "source": [
        "**Student's answer:**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **References:**"
      ],
      "metadata": {
        "id": "pzBsjCvS_kEw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Remember to cite your sources here as well! At the least, your textbook should be cited. Google Scholar allows you to effortlessly copy/paste an APA citation format for books and publications. Also cite StackOverflow, package documentation, and other meaningful internet resources to help your peers learn from these (and to avoid plagiarism claims)."
      ],
      "metadata": {
        "id": "2kr8Q-9T_nAb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "–°—Å—ã–ª–∫–∏ –Ω–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–∏, –≤ –∫–æ—Ç–æ—Ä—ã—Ö –µ—Å—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ –¥–∞—Ç–∞—Å–µ—Ç—É:\n",
        "\n",
        "https://en.wikipedia.org/wiki/Quasi-star\n",
        "\n",
        "https://en.wikipedia.org/wiki/Star\n",
        "\n",
        "https://en.wikipedia.org/wiki/Galaxy"
      ],
      "metadata": {
        "id": "YBOWgOswUSK7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font size=5>‚åõ</font> <strong><font color=orange size=5>Do not exceed competition's runtime limit!</font></strong>\n",
        "\n",
        "<hr color=red>\n"
      ],
      "metadata": {
        "id": "DoF2GoB_QGw9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tmr.ShowTime()    # measure Colab's runtime. Do not remove. Keep as the last cell in your notebook."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bD1sdgYbNWQA",
        "outputId": "4b9eef3b-5170-4048-b208-b4677c994fd4"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Runtime is 55 sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUStTaN4uo_Z"
      },
      "source": [
        "## üí°**Starter Ideas**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Tune model hyperparameters\n",
        "1. Try to linear and non-linear feature normalization: shift/scale, log, divide features by features (investigate scatterplot matrix)\n",
        "1. Try higher order feature interactions and polynomial features on a small subsample. Then identify key features or select key principal components. The final model can be trained on a larger or even full training sample. You can use [PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) to reduce the feature set\n",
        "1. Do a thorough EDA: look for feature augmentations that result in linear decision boundaries between pairs of classes.\n",
        "1. Evaluate predictions and focus on poorly predicted \"groups\":\n",
        "  1. Strongest missclassifications. E.g. the model is very confident about the wrong label\n",
        "  1. Evaluate predictions near decision boundaries.\n",
        "1. Do scatter plots show piecewise linear shape? Can a separate linear model be used on each support, or can the pattern be linearized via transformations?\n",
        "1. How are date/categorical features treated by the model? Is there a [better way](https://www.google.com/search?q=ways+to+encode+categorical+data) to encode these (perhaps, ordinal) features? \n",
        "  1. E.g. you could replace codes (or groups of codes) with their frequencies, which may capture the implied \"distance\" or rarity between category levels.\n",
        "  1. If encoding ordinal features with integers, should non-equidistant values be considered?\n",
        "1. Learn astronomy domain and features: [üé¶](https://www.youtube.com/results?search_query=Quasi-star), [quasi-star](https://en.wikipedia.org/wiki/Quasi-star), [star](https://en.wikipedia.org/wiki/Star), [galaxy](https://en.wikipedia.org/wiki/Galaxy), [üìÉ](https://arxiv.org/abs/2112.02026)\n"
      ],
      "metadata": {
        "id": "q4QO-u3t8xAO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Team 5 - Shamteev Georgy, Andrew Vasin, Maksim Kislov"
      ],
      "metadata": {
        "id": "lFU_cSWYUzGd"
      }
    }
  ]
}